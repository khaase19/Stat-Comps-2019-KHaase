---
header-includes:
- \usepackage{amssymb,amsthm,amsmath}
- \usepackage{chemarr}
output: pdf_document
---

<!--
You can delete the header-includes (lines 3-5 above) if you like and also the chunk below since it is loaded in the skeleton.Rmd file.  They are included so that chap2.Rmd will compile by itself when you hit Knit PDF.
-->

# Application to Health Data {#typeset-equ}

```{r, warning= FALSE, include= FALSE}
#loading in packages
library(readr)
library(factoextra)
library(NbClust)
library(ggplot2)
library(cluster)
library(GGally)
library(knitr)
library(xtable)
options(xtable.comment=FALSE)
```

## Exploring the Data
In this example, I will further explore the data from my Stat 495 final project. The data is from DataUSA, which uses public US Government data to analyze and visualize relationships. In the previous project, we decided to use data from 2016 because of size restrictions. The data contains spatial information, quantitative, and a few categorical variables.

The data contains demographic information, latitude and longitude, and variables that are indicators of health status. The health status variables include: poor to fair health (the percentage of adults reporting fair or poor health (age-adjusted)), poor physical health days (average number of physically unhealthy days reported in the past 30 days (age-adjusted)), physical inactivity (the percentage of adults aged 20 and over reporting no leisure-time physical inactivity), and adult obesity (the percentage of adults to report a BMI of greater than or equal to 30). In interpreting the health indicator variables, the higher the values for these variables, the less healthy a person is.  

For our Stat 495 project, we used mapping techniques to visualize and analyze our data. The only significant relationships we were able to find were between demographic information and health status; we were unable to relate health status with location. I am interested in analyzing the data through clustering, to further analyze whether the location of an observation is related to one's health status. Since clustering utilizes spatial information, it may be helpful in finding patterns in the data. 

My research question is to see whether there are clusters of people with exceptionally good or exceptionally poor health. This information could lead to further insights into what environmental or other factors are impacting peoples' health. 

I plan to use the CLARA method, since I have more than 100 observations. The data set in fact has over 60,000 observations, so I will need to sample about 1000 observations in order to produce the best results using CLARA.

My first step is to import the data. 

```{r, warning= FALSE, include= FALSE}
#using data from final stat 495 project
data_subset <- read_csv("CopyOfdata_subset.csv")
```

Next, I will take a random sample of 1000 observations. I assume the sample is representative of the data set because n=1000. 

```{r, warning= FALSE}
set.seed(1)
#getting a sample of 1000 observations
mysample <- data_subset[sample(1:nrow(data_subset), 1000,
   replace=FALSE),]
```

The data set I imported has 64 variables, which are too many for this example. Since my research question is focused around peoples' health, I will only include the health indicator variables and the latitude and longitude of the data (spatial information).

```{r, warning= FALSE}
#only keeping the variables I want to look at
myvars <- c("Latitude_tri", "Longitude_tri", "poor_or_fair_health", 
            "poor_physical_health_days", "physical_inactivity", "adult_obesity")
smallsample <- mysample[myvars]
```

The data is now ready to apply CLARA. 

## Applying CLARA
Step 1: Determining _k_. 

One of the major steps in clustering algorithms is determining how many _k_ clusters is appropriate. In Chapter 1, I explained the Elbow and Silhouette methods of determining _k_. I will perform both methods on this data to start. 

```{r}
#finding k with project data, using Elbow Method
new<- na.omit(smallsample)

elbow<- fviz_nbclust(new, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method"); elbow

fviz_nbclust(new, kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")
```

According to the Elbow method, _k_ should be 4 (where the elbow is in the graph). According to the Silhouette method, _k_ should be 2 (the maximum point in the graph). Since there is variation in values of _k_ for these methods I will take the average of the two to determine _k_. 

Step 2: Run CLARA function

Next, I will run the CLARA algorithm on the data, using the criteria of $k$=3. 

```{r}
## run CLARA
clarasamp <- clara(new[1:6], 3)
```

```{r}
## print components of clara
print(clarasamp)
```

This output tells us a lot about the results of the clustering. To start, the information from the Medoids section show that cluster 3 contains people with the worst health, in comparison to cluster 1 and 2. For example, cluster 1 and 2 average 3.7 *poor_physical_health_days*, while cluster 3 averages 4.6. This difference was seen in all four health indicator variables. 

The cluster sizes are also noted. There are 457 observations in cluster 1, 205 in cluster 2, and 263 in cluster 3. 

```{r, eval=FALSE}
#more output from CLARA

#cluster number for each observation
clarasamp$cluster
#silhouette width for each cluster
clarasamp$silinfo
```

This information tells us even more about the CLARA output. The first part gives us the categorizations of each data point to its cluster. The second part of information gives us the average silhouette width for each cluster. The silhouette widths were: 0.422183 for cluster 1, 0.634548 for cluster 2, and 0.172013 for cluster 3. The better the clustering is, the greater the silhouette width; so we can determine that cluster 2 was best compared to cluster 1 and 3. 

Next, I will walk through some of the visualizations given this new clustering information.

```{r}
## plot clusters
plot(new, col = clarasamp$cluster)
## plot centers
points(clarasamp$centers, col = 1:2, pch = 8)
```

The plot of the clusters does not look great. Aside from comparing longitude with the other variables, the plots have entirely overlapping clusters. This indicates that the CLARA method was unable to find great patterns in the data.

Next, I will use a version of a ggplot to plot the clusters. 
```{r} 
#plotting clara
factoextra::fviz_cluster(clarasamp)
```

## Evaluation of CLARA

There are multiple ways to determine the effectiveness of CLARA and the quality of its clusters. One of the ways to internally validate the method, is to look at its WSS. If there is a high WSS, it is likely the method did not work very well. 

I plotted in the previous section in the Elbow method plot to determine the number of clusters to use. Since I decided to use _k_=3 clusters, I can now go back and calculate the WSS for the method. 

```{r}
elbow
```

The Elbow method when $k$=3, shows a WSS to be about 30,000. This is very high, which is a concern when interpreting the cluster results.

Another method is to look at the silhouette width of the cluster. As mentioned in Chapter 1 the Silhouette method helps us determine how many clusters best fits the data. The Silhoutte widths of the cluster determine how well an object truly belongs to its assigned cluster. Based on many experiments and research, a silhouette width of 0.71-1 indicates a strong cluster, 0.51-0.7 indicates a resonable cluster, 0.26-0.5 indicates a weak or artifical cluster, and less than or equal to 0.25 indicates no cluster found. 

In this example, the silhouette widths were: 0.422183 for cluster 1, 0.634548 for cluster 2, and 0.172013 for cluster 3. In analyzing these values, cluster 1 is a weak or artifical cluster, cluster 2 is a reasonable cluster, and cluster 3 indicates no cluster found. 

The overall evaluation of CLARA with this data is that the algorithm did not work well. The clusters were very weak, therefore, one should not draw conclusions based on the results from this analysis. 

### Model to Predict Cluster

The CLARA method found three clusters to group the health data. While the WSS value and silhouette widths of the clusters indicated the clustering may not be very accurate or useful, I still want to investigate if I can predict the cluster number (1, 2, or 3), given the health indicator variables. This would be helpful information, if I wanted to categorize a new observation, given its values for the health variables used. 

To start this process, I first had to include a variable with cluster number (from the CLARA method) to the original sample of the data set. 

```{r}
#adding each data point's cluster #
cluster<- clarasamp$clustering
cluster_data<- cbind(new, cluster)
```

Next, I looked at possible relationships between the health indicator variables and cluster number. To start, I quickly looked at a multivariate linear regression model to predict cluster using all of the possible variables.  

```{r, warning= FALSE}
kitchen_sink<- lm(cluster~., data=cluster_data)
#summary(kitchen_sink)
```

```{r, results= 'asis', echo= FALSE}
xtable(kitchen_sink, caption= "Kitchen Sink Model")
```

According to this model, *longitude*, *poor_or_fair_health*, *poor_physical_health_days*, and physical_inactivity were strong predictors of cluster number. Overall, the model seemed to fit the data fairly well. The model had a high F-statistic and a low p-value of <2e-16. The adjusted R-squared value was 0.372.

In analyzing this model I realized that latitude and longitude were used as quantitative variables instead of categorical. Since linear and multivariate regression predictive models only use quantitative or categorical variables, I realized that the latitude and longitude (spatial information) would not be helpful.

```{r, warning= FALSE}
#taking out latitude and longitude
vars <- names(cluster_data) %in% c("Latitude_tri", "Longitude_tri")
cluster_data_new <- cluster_data[!vars]
```

I ran another kitchen sink model, with only the health variables and cluster information.

```{r, warning= FALSE}
new_kitchen_sink<- lm(cluster~., data=cluster_data_new)
#summary(new_kitchen_sink)
```

```{r, results= 'asis', echo= FALSE}
xtable(new_kitchen_sink, caption= "Updated Kitchen Sink Model")
```

This model had three significant predictors (*poor_or_fair_health*, *poor_physical_health_days*, and *adult_obesity*), a high F-statistic, and a low p-value of <2e-16. The model did not fit the data very well, and had an adjusted R-squared value of 0.155.

Next, I looked at the possible correlations between cluster number and the health indicator variables. I predicted the healthier people (lower scores on the health indicator variables) would be in cluster 1, while the least healthy people (higher scores on health indicator variables) would be in cluster 3. I also predicted the health indicator variables would be highly correlated with each other, considering they all are aiding in predicting one's health.

```{r, warning= FALSE}
ggpairs(cluster_data_new)
```

The correlation plot shows strong positive correlations between *poor_or_fair_health*, *poor_physical_health_days*, *physical_inactivity*, and *adult_obesity*, as I had predicted. The highest correlation was 0.884, between *poor_physical_health_days* and *poor_to_fair_health*. All of the variables in general show bell-shaped curves with a relatively even shape. 

The plots comparing the variables to the cluster number are hard to interpret at first. To start, the *poor_to_fair_health* versus cluster plot shows that the highest values of *poor_or_fair_health* are in cluster 3. These look to be possible outliers, but regardless, it confirms the prediction that the unhealthy people (high health variable scores) are in cluster 3. 

The *poor_physical_health_days* versus cluster number and adult_obesity versus cluster number show a couple of observations with high health variable scores in cluster 3 as well. It is again unclear if these points are outliers or not.

In general, the plots show that cluster 2 has the smallest range of health scores, which further confirms that cluster 2 had the highest quality of clustering (the largest silhouette width). In terms of correlation values, cluster number was shows to be sightly negatively correlated with poor_physical_health_days, with a correlation value of -0.25. 

I had predicted the correlation to be positive, because the CLARA output revealed cluster 3 to have the most unhealthy people. This would mean the higher the health variable value, the higher the cluster number. Since the correlations are in fact slightly negative, I believe the reason for the higher health value mean score for cluster 3 was probably due to the outliers also shown in the plots. 

All of correlations between the health variables and cluster number were negative, indicating that the clustering was not very effective and instead there may be outliers impacting the original analysis of CLARA.

Nevertheless, I will continue to explore possible relationships between health variables and cluster number. Based on the correlation plot, I will explore *poor_or_fair_health* (because of the plot), *poor_physical_health_days* (because of the correlation value), and *adult_obesity* (because of the plot).

I tried numerous combinations of the variables as well as interaction terms, because the variables are so highly correlated. 

```{r, include= FALSE, echo= FALSE}
set.seed(2)
#exploring possible relationships between health variables and cluster number

fun1<- lm(cluster~ poor_or_fair_health + poor_physical_health_days + adult_obesity, data= cluster_data_new)
#low adjusted R-squared (0.155), but significant predictors
 
fun2<- lm(cluster~ poor_or_fair_health, data= cluster_data_new)
fun3<- lm(cluster~ poor_physical_health_days, data= cluster_data_new)
fun4<- lm(cluster~ adult_obesity, data= cluster_data_new)
#low adjusted R-squared, highest of the 3 functions was 0.06

fun5<- lm(cluster~ poor_or_fair_health + poor_physical_health_days + adult_obesity + poor_or_fair_health:poor_physical_health_days, data= cluster_data_new)
#added an interaction, raised the adjusted R-squared to 0.165

fun6<- lm(cluster~ poor_or_fair_health + poor_physical_health_days + adult_obesity + poor_physical_health_days:adult_obesity, data= cluster_data_new)
#tried a different interaction, about the same adjusted R-squared

fun7<- lm(cluster~ poor_or_fair_health + poor_physical_health_days + adult_obesity + poor_or_fair_health:adult_obesity, data= cluster_data_new)
#last combination of an interaction, highest adjusted R-squared yet (0.175)!
#only predictor not significant was poor_or_fair_health

fun8<- lm(cluster~  poor_physical_health_days + adult_obesity + poor_or_fair_health:adult_obesity, data= cluster_data_new)
#dropped poor_or_fair_health, about the same adjusted R-squared (0.174)

fun9<- lm(cluster~ poor_physical_health_days + adult_obesity + poor_physical_health_days:adult_obesity, data= cluster_data_new)
#tried a different interaction, low adjusted R-squared (0.0958)

fun10<- lm(cluster~ poor_physical_health_days + adult_obesity + poor_or_fair_health:poor_physical_health_days, data= cluster_data_new)
#tried last combination of interaction, adjusted R-squared= 0.166
```

Most of the model had significant predictors; however, the R-squared values were small; indicating that the models did not fit the data very well.

In comparing adjusted R-squared values and the number of predictors used, the best model ended up being:
```{r}
summary(fun8)
```

This model used three predictors and had about the same R-squared value as the previous model, with one less predictor. 

